{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Antimalware_Android_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/projectmatris/antimalwareapp_ml/blob/master/Antimalware_Android_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivdm21LJKQHf"
      },
      "source": [
        "# **ANTIMALWARE FOR ANDROID USING MACHINE LEARNING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x6Dti2amQ1E"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwrkyMWBmHnq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create project directory - uncomment and execute the below cell when running this notebook for the first time."
      ],
      "metadata": {
        "id": "_Hq0lChQ8f8s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VytJRqnmVKf"
      },
      "source": [
        "# %cd gdrive/My\\ Drive/\n",
        "# !mkdir ProjectFiles\n",
        "# %cd ProjectFiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigate to project directory"
      ],
      "metadata": {
        "id": "d86ZHVfG81mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/My\\ Drive/ProjectFiles"
      ],
      "metadata": {
        "id": "qhp8iMxI84O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpD4yG8BBY-W"
      },
      "source": [
        "### **Set up kaggle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpqk4PbgEHUp"
      },
      "source": [
        "First create an account in kaggle  \n",
        "Then create new API token  \n",
        "This will download a file into your computer  (kaggle.json)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cfnVgV3BfQz"
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj06i2mZENjV"
      },
      "source": [
        "Upload kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdcjpD4gBjfF"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o71c2VVoERzE"
      },
      "source": [
        "Run this code to copy the API key to the kaggle directory we created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x59FwWPsBkIP"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHwWr7XEEY3s"
      },
      "source": [
        "Now the datasets should be available for us to use. To check this, let us list the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrhjJoGVBotH"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zre1YWoABrKd"
      },
      "source": [
        "### **Working with datasets (Feature Extraction)**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCj3AqXGEhEl"
      },
      "source": [
        "Download the required datasets from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGEWY9AFB3es"
      },
      "source": [
        "!kaggle datasets download -d goorax/static-analysis-of-android-malware-of-2017"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7s7H3qfB4cP"
      },
      "source": [
        "!kaggle datasets download -d goorax/static-analysis-of-android-benign-apps-of-2017"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLrnhVlZElTU"
      },
      "source": [
        "Unzip the downloaded datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Z90r7pB7pU"
      },
      "source": [
        "!unzip static-analysis-of-android-malware-of-2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeqfTBERB9i7"
      },
      "source": [
        "!unzip static-analysis-of-android-benign-apps-of-2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KdlBNUyEtal"
      },
      "source": [
        "List the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myx1QYf9B_7Q"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mFuDkVmnEde"
      },
      "source": [
        "Extract permissions from datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt8Sq6qmmgSw"
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def remove_duplicates():\n",
        "  lines_seen = set() # holds lines already seen\n",
        "  outfile = open(\"all_permissions.txt\", \"w\")\n",
        "  for line in open(\"permissions.txt\", \"r\"):\n",
        "    if line not in lines_seen: # not a duplicate\n",
        "      outfile.write(line)\n",
        "      lines_seen.add(line)\n",
        "  outfile.close()\n",
        "\n",
        "def extract_permissions(filepath):\n",
        "  with open(filepath) as f:\n",
        "    data = json.load(f)\n",
        "    permissions = data[\"permissions\"]\n",
        "    with open(\"permissions.txt\",\"a+\") as pfile:\n",
        "      pfile.seek(0)\n",
        "      pfromfile = pfile.readlines()\n",
        "      for permission in permissions:\n",
        "        if(permission+\"\\n\" not in pfromfile):\n",
        "          pfile.write(permission+\"\\n\")\n",
        "          print(\"Written \"+permission+\" to file.\")\n",
        "\n",
        "\n",
        "paths = [\"./benign_2017_static/ApkMetaReport/\",\"./malware_2017_static/ApkMetaReport/\"]\n",
        "for path in paths:\n",
        "  files = os.listdir(path)\n",
        "  for file in files:\n",
        "    print(file)\n",
        "    filepath = path + file\n",
        "    extract_permissions(filepath)\n",
        "  remove_duplicates()\n",
        "print(\"Permissions stored in all_permissions.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6kBZA22nZ9c"
      },
      "source": [
        "Extract intents from datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-VrWzYfnICm"
      },
      "source": [
        "def remove_duplicates():\n",
        "  lines_seen = set() # holds lines already seen\n",
        "  outfile = open(\"all_intents.txt\", \"w\")\n",
        "  for line in open(\"intents.txt\", \"r\"):\n",
        "    if line not in lines_seen: # not a duplicate\n",
        "      outfile.write(line)\n",
        "      lines_seen.add(line)\n",
        "  outfile.close()\n",
        "\n",
        "def extract_intents(filepath):\n",
        "  with open(filepath) as f:\n",
        "    data = json.load(f)\n",
        "    intents = data[\"intents\"]\n",
        "    with open(\"intents.txt\",\"a+\") as ifile:\n",
        "      ifile.seek(0)\n",
        "      ifromfile = ifile.readlines()\n",
        "      for intent in intents:\n",
        "        if(intent+\"\\n\" not in ifromfile):\n",
        "          ifile.write(intent+\"\\n\")\n",
        "          print(\"Written \"+intent+\" to file.\")\n",
        "\n",
        "\n",
        "paths = [\"./benign_2017_static/ApkMetaReport/\",\"./malware_2017_static/ApkMetaReport/\"]\n",
        "for path in paths:\n",
        "  files = os.listdir(path)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "    print(file)\n",
        "    filepath = path + file\n",
        "    extract_intents(filepath)\n",
        "remove_duplicates()\n",
        "print(\"Intents stored in all_intents.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3maKQG2noSX"
      },
      "source": [
        "Write permissions and intents to constants.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYxDIHNTnnVz"
      },
      "source": [
        "pfile = open(\"all_permissions.txt\", \"r\")\n",
        "data = pfile.readlines()\n",
        "for i in range(len(data)):\n",
        "  data[i] = data[i].replace('\\n', '')\n",
        "with open(\"constants.py\",\"w\") as cons:\n",
        "  cons.write(\"PERMISSIONS=(\")\n",
        "  for p in data[:-1]:\n",
        "    if(p!=\"\"):\n",
        "      cons.write(\"'\"+str(p)+\"'\")\n",
        "      cons.write(\",\\n\")\n",
        "  cons.write(\"'\")\n",
        "  cons.write(str(data[-1]))\n",
        "  cons.write(\"'\")\n",
        "  cons.write(\")\")\n",
        "pfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCrWtQxOnuRI"
      },
      "source": [
        "ifile = open(\"all_intents.txt\", \"r\")\n",
        "data = ifile.readlines()\n",
        "for i in range(len(data)):\n",
        "  data[i] = data[i].replace('\\n', '')\n",
        "with open(\"constants.py\",\"a\") as cons:\n",
        "  cons.write(\"\\n\")\n",
        "  cons.write(\"INTENTS=(\")\n",
        "  for i in data[:-1]:\n",
        "    if(i!=\"\"):\n",
        "      cons.write(\"'\"+str(i)+\"'\")\n",
        "      cons.write(\",\\n\")\n",
        "  cons.write(\"'\")\n",
        "  cons.write(str(data[-1]))\n",
        "  cons.write(\"'\")\n",
        "  cons.write(\")\\n\")\n",
        "ifile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIXIWilYn7Fr"
      },
      "source": [
        "Select features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrjGrgpbnwws"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "from constants import PERMISSIONS\n",
        "from constants import INTENTS\n",
        "\n",
        "\n",
        "def load_json(fp):\n",
        "  data = {}\n",
        "  with open(fp) as f:\n",
        "    data = json.load(f)\n",
        "  return data[\"permissions\"],data[\"intents\"]\n",
        "\n",
        "def get_feature_vector(apk):\n",
        "  fv = [] #feature vector\n",
        "  for permission in PERMISSIONS:\n",
        "    status = 1 if permission in apk['permissions'] else 0\n",
        "    fv.append(status)\n",
        "  for intent in INTENTS:\n",
        "    status = 1 if intent in apk['intents'] else 0\n",
        "    fv.append(status)\n",
        "  return fv\n",
        "\n",
        "def prepare_dataset():\n",
        "  paths = [\"./benign_2017_static/ApkMetaReport/\",\"./malware_2017_static/ApkMetaReport/\"]\n",
        "  apks = []\n",
        "  for path in paths:\n",
        "    files = os.listdir(path)\n",
        "    for file in files:\n",
        "      apk = {}\n",
        "      filepath = path + file\n",
        "      apk['permissions'],apk['intents']= load_json(filepath)\n",
        "      apk['Malicious'] = paths.index(path) \n",
        "      apks.append(apk)\n",
        "  return apks\n",
        "\n",
        "def get_X_and_Y_matrices():\n",
        "  print(\"Preparing dataset...\")\n",
        "  dataset = prepare_dataset()\n",
        "  print(\"Dataset preparation completed.\")\n",
        "  print(\"Creating x and y matrices...\")\n",
        "  x = []\n",
        "  y = []\n",
        "  for apk in dataset:\n",
        "    x.append(get_feature_vector(dataset[dataset.index(apk)]))\n",
        "    y.append(apk['Malicious'])\n",
        "  print(\"x and y matrices are created.\")\n",
        "  return np.array(x),np.array(y)\n",
        "\n",
        "print(\"Fetching X and Y matrices...\")\n",
        "X, Y = get_X_and_Y_matrices()\n",
        "print(\"X and Y matrices are fetched.\")\n",
        "print(len(Y))\n",
        "input_dim=len(X[0])\n",
        "print(\"Feature selection\")\n",
        "\n",
        "test = SelectKBest(score_func=f_classif, k=2000)\n",
        "fit = test.fit(X, Y)\n",
        "print(fit.scores_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yreDnvAesONv"
      },
      "source": [
        "features = fit.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrEqABwisRT5"
      },
      "source": [
        "indices = fit.get_support(True) # returns array of indices of selected features\n",
        "mask = fit.get_support()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G53FxsXBA5-D"
      },
      "source": [
        "Write selected features into selected_features.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hxLf6SiA1-y"
      },
      "source": [
        "from constants import PERMISSIONS\n",
        "from constants import INTENTS\n",
        "print(len(indices))\n",
        "print(len(mask))\n",
        "print(mask)\n",
        "\n",
        "intentstartindex = 0\n",
        "permissionslastindex = 0\n",
        "\n",
        "for i in range(len(indices)):\n",
        "  if(indices[i]<len(PERMISSIONS)):\n",
        "    continue\n",
        "  else:\n",
        "    intentstartindex = i\n",
        "    permissionslastindex = i-1\n",
        "    break\n",
        "\n",
        "print(\"PERMISSIONS:\"+str(len(PERMISSIONS)))\n",
        "print(\"INTENTS:\"+str(len(INTENTS)))\n",
        "print(\"permissionslastindex:\"+str(permissionslastindex))\n",
        "print(\"indices[permissionslastindex]:\"+str(indices[permissionslastindex]))\n",
        "print(\"intentstartindex:\"+str(intentstartindex))\n",
        "print(\"indices[intentstartindex]:\"+str(indices[intentstartindex]))\n",
        "\n",
        "with open(\"selected_features.py\",\"w\") as sf:\n",
        "  sf.write(\"PERMISSIONS=(\")\n",
        "  for i in range(permissionslastindex):\n",
        "      sf.write(\"'\"+str(PERMISSIONS[indices[i]])+\"'\")\n",
        "      sf.write(\",\\n\")\n",
        "  sf.write(\"'\")\n",
        "  sf.write(str(PERMISSIONS[indices[permissionslastindex]]))\n",
        "  sf.write(\"'\")\n",
        "  sf.write(\")\\n\")\n",
        "  sf.write(\"INTENTS=(\")\n",
        "  for i in range(intentstartindex,len(indices)-1):\n",
        "      sf.write(\"'\"+str(INTENTS[indices[i]-len(PERMISSIONS)])+\"'\")\n",
        "      sf.write(\",\\n\")\n",
        "  sf.write(\"'\")\n",
        "  sf.write(str(INTENTS[indices[-1]-len(PERMISSIONS)]))\n",
        "  sf.write(\"'\")\n",
        "  sf.write(\")\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selected_features import PERMISSIONS\n",
        "from selected_features import INTENTS\n",
        "\n",
        "print(\"Number of permissions selected:\"+str(len(PERMISSIONS)))\n",
        "print(\"Numebr of intents selected:\"+str(len(INTENTS)))"
      ],
      "metadata": {
        "id": "2GsXuXz2XMAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj8kVjKuvPbO"
      },
      "source": [
        "### **Train the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrTxuilvaoE"
      },
      "source": [
        "Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noste-2RvUow"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size = 0.2, random_state = 42)\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyIayR-Syk_d"
      },
      "source": [
        "Apply GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bogmWxzvcvu"
      },
      "source": [
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.layers import Dropout\n",
        "# from keras.constraints import maxnorm\n",
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn import metrics\n",
        "\n",
        "# def create_model(optimizer='rmsprop', init_mode='uniform', activation='relu', neurons=30, dropout_rate=0.0, weight_constraint=0):\n",
        "#   keras_model = Sequential()\n",
        "#   keras_model.add(Dense(neurons, activation=activation, input_dim=2000, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
        "#   keras_model.add(Dropout(dropout_rate))\n",
        "#   keras_model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "#   keras_model.compile(optimizer=optimizer,\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "#   return keras_model\n",
        "\n",
        "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# batch_size = [10, 15, 20, 25, 30]\n",
        "# epochs = [50, 100, 250, 500]\n",
        "# # optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "# # init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "# # activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "# # neurons = [20, 30, 40, 50, 60]\n",
        "# # dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "# # weight_constraint = [1, 2, 3, 4, 5]\n",
        "# # learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "# # momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "# # param_grid = dict(optimizer=optimizer)\n",
        "# # param_grid = dict(init_mode=init_mode)\n",
        "# # param_grid = dict(activation=activation)\n",
        "# # param_grid = dict(neurons=neurons)\n",
        "# # param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
        "# # param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "# # param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer, init_mode=init_mode,activation=activation,neurons=neurons, dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
        "\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "# grid_result = grid.fit(features, Y)\n",
        "\n",
        "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "# means = grid_result.cv_results_['mean_test_score']\n",
        "# stds = grid_result.cv_results_['std_test_score']\n",
        "# params = grid_result.cv_results_['params']\n",
        "# for mean, stdev, param in zip(means, stds, params):\n",
        "#   print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vhbqVPt31N5"
      },
      "source": [
        "Train the network using above parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjL4oi2f-V57"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from selected_features import PERMISSIONS\n",
        "from selected_features import INTENTS\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from keras.constraints import maxnorm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "def load_json(fp):\n",
        "  data = {}\n",
        "  with open(fp) as f:\n",
        "    data = json.load(f)\n",
        "  return data[\"permissions\"],data[\"intents\"]\n",
        "\n",
        "def get_feature_vector(apk):\n",
        "  fv = [] #feature vector\n",
        "  for permission in PERMISSIONS:\n",
        "    status = 1 if permission in apk['permissions'] else 0\n",
        "    fv.append(status)\n",
        "  for intent in INTENTS:\n",
        "    status = 1 if intent in apk['intents'] else 0\n",
        "    fv.append(status)\n",
        "  return fv\n",
        "\n",
        "def prepare_dataset():\n",
        "  paths = [\"./benign_2017_static/ApkMetaReport/\",\"./malware_2017_static/ApkMetaReport/\"]\n",
        "  apks = []\n",
        "  for path in paths:\n",
        "    files = os.listdir(path)\n",
        "    for file in files:\n",
        "      apk = {}\n",
        "      filepath = path + file\n",
        "      apk['permissions'],apk['intents']= load_json(filepath)\n",
        "      apk['Malicious'] = paths.index(path) \n",
        "      apks.append(apk)\n",
        "  return apks\n",
        "\n",
        "def get_X_and_Y_matrices():\n",
        "  print(\"Preparing dataset...\")\n",
        "  dataset = prepare_dataset()\n",
        "  print(\"Dataset preparation completed.\")\n",
        "  print(\"Creating x and y matrices...\")\n",
        "  x = []\n",
        "  y = []\n",
        "  for apk in dataset:\n",
        "    x.append(get_feature_vector(dataset[dataset.index(apk)]))\n",
        "    y.append(apk['Malicious'])\n",
        "  print(\"x and y matrices are created.\")\n",
        "  return np.array(x),np.array(y)\n",
        "\n",
        "print(\"Fetching X and Y matrices...\")\n",
        "X, Y = get_X_and_Y_matrices()\n",
        "print(\"X and Y matrices are fetched.\")\n",
        "print(len(Y))\n",
        "\n",
        "#split the dataset for training and testing\n",
        "print(\"Splitting the dataset...\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
        "print(len(y_train))\n",
        "print(len(y_test))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='relu', input_dim=2000, kernel_initializer='lecun_uniform', kernel_constraint=maxnorm(2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, kernel_initializer='lecun_uniform', activation='sigmoid'))\n",
        "#optimizer = SGD(lr=0.001, momentum=0.6)\n",
        "model.compile(optimizer='rmsprop',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=20)\n",
        "\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n",
        "predictions = list((model.predict(x_test)>0.5).astype(\"int32\"))\n",
        "print(\"Accuracy: \"+str(metrics.accuracy_score(y_test, predictions)*100)+\"%\")\n",
        "print(\"Precision: \"+str(metrics.precision_score(y_test, predictions)*100)+\"%\")\n",
        "print(\"Recall: \"+str(metrics.recall_score(y_test, predictions)*100)+\"%\")\n",
        "print(\"F1-Score: \"+str(metrics.f1_score(y_test, predictions)*100)+\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91mjatrqkiXW"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aPN6yu9kd-g"
      },
      "source": [
        "model.reset_metrics()\n",
        "# Export the model to a SavedModel\n",
        "model.save('SavedModel', save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgcN2TtpkoD4"
      },
      "source": [
        "Convert the model to tflite format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szNuZwgDkklA"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('SavedModel')\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVSsIIFZ5egL"
      },
      "source": [
        "### **Test the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBE24enFFYNf"
      },
      "source": [
        "The following script can be used to test the model using random sample from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBZEMeOK5dMZ"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from selected_features import PERMISSIONS\n",
        "from selected_features import INTENTS\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def load_json(fp):\n",
        "  data = {}\n",
        "  with open(fp) as f:\n",
        "    data = json.load(f)\n",
        "  return data[\"permissions\"],data[\"intents\"]\n",
        "\n",
        "def get_feature_vector(apk):\n",
        "  fv = [] #feature vector\n",
        "  for permission in PERMISSIONS:\n",
        "    status = 1 if permission in apk['permissions'] else 0\n",
        "    fv.append(status)\n",
        "  for intent in INTENTS:\n",
        "    status = 1 if intent in apk['intents'] else 0\n",
        "    fv.append(status)\n",
        "  return fv\n",
        "\n",
        "def get_apk(path):\n",
        "  apk = {}\n",
        "  files = os.listdir(path)\n",
        "  file = files[random.randrange(20, 50, 3)]\n",
        "  filepath = path + file\n",
        "  apk['permissions'],apk['intents'] = load_json(filepath)\n",
        "  return apk\n",
        "\n",
        "def get_X():\n",
        "  print(\"Fetching apk...\")\n",
        "  path = random.choice([\"./benign_2017_static/ApkMetaReport/\",\"./malware_2017_static/ApkMetaReport/\"])\n",
        "  if(path==\"./benign_2017_static/ApkMetaReport/\"):\n",
        "    print(\"Original: Goodware\")\n",
        "  elif(path==\"./malware_2017_static/ApkMetaReport/\"):\n",
        "    print(\"Original: Malware\")\n",
        "  else:\n",
        "    print(\"Not chosen anything\")\n",
        "  apk = get_apk(path)\n",
        "  print(\"Fetched apk.\")\n",
        "  print(\"Creating feature vector...\")\n",
        "  x = get_feature_vector(apk)\n",
        "  print(\"Feature vector is created.\")\n",
        "  return x\n",
        "\n",
        "x = np.array(get_X())\n",
        "x=x.reshape(1,-1)\n",
        "model = keras.models.load_model('SavedModel')\n",
        "prediction = (model.predict(x)>0.5).astype(\"int32\")\n",
        "if(prediction == 1):\n",
        "  print(\"Prediction: Malware!!!\")\n",
        "elif(prediction == 0):\n",
        "  print(\"Prediction: Goodware :)\")\n",
        "else:\n",
        "  print(\"Some error occured. Please check again.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}